name: Daily Menu Scraper

on:
  schedule:
    - cron: '5 8 * * 1-5'
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape-and-notify:
    runs-on: ubuntu-latest
    # Only run scheduled jobs on main branch, allow manual triggers on any branch
    if: github.event_name != 'schedule' || github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip' # Enable pip caching
        
    - name: Cache Playwright browsers
      uses: actions/cache@v4
      with:
        path: ~/.cache/ms-playwright
        key: playwright-${{ runner.os }}-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          playwright-${{ runner.os }}-

    - name: Cache and Install APT packages
      uses: awalsh128/cache-apt-pkgs-action@latest
      with:
        packages: libasound2t64 libatk1.0-0 libatk-bridge2.0-0 libcups2 libdrm2 libgbm1 libnss3 libpango-1.0-0 libxcomposite1 libxdamage1 libxfixes3 libxrandr2 libxkbcommon0 libwayland-client0 libglu1-mesa xvfb
        version: 1.0
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright
      run: |
        playwright install chromium
        
    - name: Run menu scraper
      env:
        GOOGLE_CHAT_WEBHOOK_URL: ${{ secrets.GOOGLE_CHAT_WEBHOOK_URL }}
        FACEBOOK_PAGE_URL: ${{ secrets.FACEBOOK_PAGE_URL }}
        LOG_LEVEL: INFO
      run: |
        python3 src/main.py
        
    - name: Report failure
      if: failure()
      env:
        GOOGLE_CHAT_WEBHOOK_URL: ${{ secrets.GOOGLE_CHAT_WEBHOOK_URL }}
      run: |
        curl -X POST -H "Content-Type: application/json" -d '{"text": "⚠️ Menu scraping failed! Please check GitHub Actions for details."}' $GOOGLE_CHAT_WEBHOOK_URL
